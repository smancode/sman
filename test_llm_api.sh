#!/bin/bash

# æµ‹è¯• LLM API è¿æ¥
# ç”¨æ³•: ./test_llm_api.sh

echo "=== SmanAgent LLM API æµ‹è¯• ==="
echo ""

# æ£€æŸ¥ç¯å¢ƒå˜é‡
if [ -z "$LLM_API_KEY" ]; then
    echo "âŒ é”™è¯¯: LLM_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®"
    echo ""
    echo "è¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡:"
    echo "  export LLM_API_KEY=your_api_key_here"
    echo ""
    exit 1
fi

echo "âœ… API Key å·²è®¾ç½® (é•¿åº¦: ${#LLM_API_KEY})"
echo ""

# æµ‹è¯• API ç«¯ç‚¹
API_URL="https://open.bigmodel.cn/api/paas/v4/chat/completions"

echo "ğŸ“¡ æµ‹è¯• API ç«¯ç‚¹: $API_URL"
echo ""

# æ„å»ºæµ‹è¯•è¯·æ±‚
curl -s -X POST "$API_URL" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $LLM_API_KEY" \
  -d '{
    "model": "glm-4-flash",
    "messages": [
      {"role": "user", "content": "ä½ å¥½ï¼Œè¯·å›å¤\"æµ‹è¯•æˆåŠŸ\""}
    ],
    "max_tokens": 50
  }' > /tmp/llm_test_response.json

# æ£€æŸ¥å“åº”
if [ $? -eq 0 ]; then
    echo "âœ… HTTP è¯·æ±‚æˆåŠŸ"
    echo ""

    # è§£æå“åº”
    HTTP_CODE=$(cat /tmp/llm_test_response.json | jq -r '.object // "error"')

    if [ "$HTTP_CODE" = "chat.completion" ]; then
        echo "âœ… API è°ƒç”¨æˆåŠŸ"
        echo ""
        echo "ğŸ“ å“åº”å†…å®¹:"
        cat /tmp/llm_test_response.json | jq -r '.choices[0].message.content'
        echo ""
        echo "ğŸ“Š å®Œæ•´å“åº”:"
        cat /tmp/llm_test_response.json | jq '.'
        exit 0
    else
        echo "âŒ API è¿”å›é”™è¯¯:"
        cat /tmp/llm_test_response.json | jq '.'
        exit 1
    fi
else
    echo "âŒ HTTP è¯·æ±‚å¤±è´¥"
    exit 1
fi
