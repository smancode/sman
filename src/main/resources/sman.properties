# Sman 配置文件
# 支持环境变量占位符：${ENV_VAR_NAME}

# ==================== LLM API 配置 ====================
llm.api.key=${LLM_API_KEY}
# 使用 coding 专用端点（与 agent 项目保持一致）
llm.base.url=https://open.bigmodel.cn/api/coding/paas/v4
llm.model.name=GLM-5
llm.response.max.tokens=28192

# ==================== 重试配置 ====================
# 最大重试次数
llm.retry.max=3
# 重试基础延迟（毫秒）
# 429 错误需要更长的等待时间，建议至少 5 秒
llm.retry.base.delay=5000

# ==================== 超时配置（毫秒）===================
llm.timeout.connect=30000
llm.timeout.read=300000
llm.timeout.write=30000

# ==================== ReAct 循环配置 ====================
react.max.steps=25
react.enable.streaming=true

# ==================== 上下文压缩配置 ====================
compaction.max.tokens=156000
compaction.threshold=128000
compaction.enable.intelligent=true

# ==================== 模型参数配置 ====================
llm.temperature=0.0
llm.default.max.tokens=4096

# ==================== 向量数据库配置 ====================
# 向量数据库类型: JVECTOR, MEMORY, MILVUS, CHROMA, PGVECTOR
vector.db.type=JVECTOR
vector.db.dimension=1024

# JVector 配置（L2 温数据索引）
# HNSW 参数说明：
# - dimension: BGE-M3 向量维度 (1024)
# - M: HNSW 图连接数 (8-32, 推荐 16)
# - efConstruction: HNSW 构建参数 (50-200, 推荐 100)
# - efSearch: HNSW 搜索参数 (20-100, 推荐 50)
# - enablePersist: 是否启用磁盘持久化
# - rerankerThreshold: Reranker 相似度阈值 (0.0-1.0, 仅定义未使用)
vector.db.jvector.dimension=1024
vector.db.jvector.M=16
vector.db.jvector.efConstruction=100
vector.db.jvector.efSearch=50
vector.db.jvector.enablePersist=true
vector.db.jvector.rerankerThreshold=0.1

# L1/L2/L3 三层缓存配置
# L1 (Hot): 内存 LRU 缓存，存储最近访问的热点数据
# - 小型项目: 100-500
# - 中型项目: 500-1000
# - 大型项目: 1000-2000
vector.db.l1.cache.size=500

# H2 数据库说明：
# - H2 是嵌入式数据库，无需外部安装
# - 路径自动按项目隔离：{projectPath}/.sman/analysis.mv.db
# - 无需手动配置路径，由 ProjectPaths 自动管理

# ==================== BGE-M3 向量化配置 ====================
# BGE-M3 服务端点（需自行部署）
# 如需启用语义搜索，请先部署 BGE-M3 服务
# 注意：只填写基础 URL，不要包含 /v1/embeddings
bge.endpoint=http://localhost:8000
bge.model.name=BAAI/bge-m3
bge.dimension=1024
bge.timeout.seconds=30
bge.batch.size=10

# BGE Token 限制（默认 8192）
bge.max.tokens=8192

# BGE 截断配置
# 截断策略: HEAD, TAIL, MIDDLE, SMART
bge.truncation.strategy=TAIL
bge.truncation.step.size=1000
bge.max.truncation.retries=10

# BGE 重试配置
bge.retry.max=3
bge.retry.base.delay=1000

# BGE 并发配置
bge.concurrent.limit=3

# BGE 熔断器配置
bge.circuit.breaker.threshold=5

# ==================== BGE-Reranker 配置 ====================
# Reranker 重排服务配置（提升搜索效率 10 倍+）
# 需自行部署 BGE-Reranker 服务
reranker.enabled=true
reranker.base.url=http://localhost:8001/v1
reranker.model=BAAI/bge-reranker-v2-m3
reranker.api.key=
reranker.timeout.seconds=30
reranker.retry=2
reranker.max.rounds=3
reranker.top.k=15
# Reranker 相似度阈值 (0.0-1.0, 推荐 0.1)
reranker.threshold=0.1

# ==================== 项目分析配置 ====================
# 强制刷新项目分析（跳过 MD5 缓存）
# 开发阶段设置为 true，每次都重新分析
# 生产环境设置为 false，利用 MD5 缓存提升性能
analysis.force.refresh=true

# ==================== LLM 代码向量化配置 ====================
# 是否启用 LLM 驱动的代码向量化（默认 false）
# 启用后会对每个源文件调用 LLM 进行精读分析，生成业务描述
# 注意：首次启用会对所有文件进行分析，后续只分析变化的文件（基于 MD5）
analysis.llm.vectorization.enabled=true

# LLM 代码向量化全量刷新（默认 false）
# 设置为 true 时，会忽略 MD5 缓存，对所有文件重新进行 LLM 分析
# 仅在需要完全重建向量数据时使用（如 LLM prompt 更新后）
analysis.llm.vectorization.full.refresh=false

# ==================== 自进化配置 ====================
# 是否启用自进化学习循环（默认 false）
# 启用后会在后台自动生成问题并探索学习
self.evolution.enabled=false

# 深度分析开关（默认 false）
# 启用后每轮生成更多问题（5个 vs 3个），探索更深入（15步 vs 10步）
# 并触发代码向量化，Token 消耗更大
self.evolution.deep.enabled=false
